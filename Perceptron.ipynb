{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6IyYtaLWZSjwWY/bertgS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreafalcon05-collab/Inteligencia-Artificial/blob/main/Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6LwsM-XxJaZt"
      },
      "outputs": [],
      "source": [
        "#Definimos las entrada x1 y x2 con sus respectivas etiquetas y1 e y2, los pesos w1 y w2, y el sesgo b.\n",
        "import numpy as np\n",
        "# Entradas para el perceptron\n",
        "X = np.array([[0, 0],\n",
        "              [0, 1],\n",
        "              [1, 0],\n",
        "              [1, 1]])\n",
        "# Salidas\n",
        "Y = np.array([0, 0, 0, 1])\n",
        "# Pesos para las entradas\n",
        "weights = np.array([1.0, 0.5])\n",
        "# Tasa de aprendizaje\n",
        "lr = 0.01\n",
        "# Epocas\n",
        "epochs = 100\n",
        "# Sesgo\n",
        "bias =  1.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Definimos clase Perceptron\n",
        "class Perceptron:\n",
        "    def __init__(self, lr, epochs, weights, bias):\n",
        "        \"\"\"\n",
        "            Constructor del perceptron:\n",
        "            Guarda las variables\n",
        "            lr -> tasa de aprendizaje\n",
        "            epochs -> numero de epocas\n",
        "            weights -> vector de pesos iniciales\n",
        "            bias -> sesgo inicial\n",
        "        \"\"\"\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.weights = weights\n",
        "        self.bias = bias\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        \"\"\"\n",
        "            Realiza el entrenamiento del Perceptron.\n",
        "        \"\"\"\n",
        "        # Recorre el dataset la cantidad indicada en epocas\n",
        "        for epoch in range(self.epochs):\n",
        "            for j in range(X.shape[0]):\n",
        "                # Calcula la salida del perceptrón para la entrada actual\n",
        "                y_pred = self.activation_function(np.dot(self.weights, X[j]) + self.bias)\n",
        "                # Calcula el error\n",
        "                loss = Y[j] - y_pred\n",
        "                # Actualiza los pesos y el sesgo\n",
        "                self.weights += self.lr * loss * X[j]\n",
        "                self.bias += self.lr * loss\n",
        "            print(f\"Epoch {epoch}, Optimized Weights are {self.weights}, and bias is {self.bias}\")\n",
        "        # Imprime los valores finales de los parámetros aprendidos\n",
        "        print(f\"Optimized Weights are {self.weights} and bias is {self.bias}\")\n",
        "\n",
        "    def activation_function(self, activation):\n",
        "        \"\"\"\n",
        "            Función de activacion escalon\n",
        "        \"\"\"\n",
        "        return 1 if activation >= 0 else 0\n",
        "\n",
        "    def prediction(self, X):\n",
        "        \"\"\"\n",
        "            Calcula la salida del Perceptron para cada fila de entradas X.\n",
        "        \"\"\"\n",
        "        # Calcula producto punto + bias para todas las entradas\n",
        "        sum_ = np.dot(X, self.weights) + self.bias\n",
        "        # Mensaje input y su predicción\n",
        "        for i, s in enumerate(sum_):\n",
        "            print(f\"Input: {X[i]}, Predictions: {self.activation_function(sum_[i])}\")\n",
        "        # Devuelve un array con todas las predicciones\n",
        "        return np.array([self.activation_function(s) for s in sum_])"
      ],
      "metadata": {
        "id": "fFbT3RVYK4qB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear una instancia del perceptrón\n",
        "p = Perceptron(lr=lr, epochs=epochs, weights=weights, bias=bias)\n",
        "# Entrenar el modelo\n",
        "p.fit(X, Y)\n",
        "# Usar el modelo entrenado para realizar predicciones\n",
        "predictions = p.prediction(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZfXGtPeLDuM",
        "outputId": "35caeae7-3d4e-44fb-9535-462fe189c3cf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Optimized Weights are [0.99 0.49], and bias is 0.97\n",
            "Epoch 1, Optimized Weights are [0.98 0.48], and bias is 0.94\n",
            "Epoch 2, Optimized Weights are [0.97 0.47], and bias is 0.9099999999999999\n",
            "Epoch 3, Optimized Weights are [0.96 0.46], and bias is 0.8799999999999999\n",
            "Epoch 4, Optimized Weights are [0.95 0.45], and bias is 0.8499999999999999\n",
            "Epoch 5, Optimized Weights are [0.94 0.44], and bias is 0.8199999999999998\n",
            "Epoch 6, Optimized Weights are [0.93 0.43], and bias is 0.7899999999999998\n",
            "Epoch 7, Optimized Weights are [0.92 0.42], and bias is 0.7599999999999998\n",
            "Epoch 8, Optimized Weights are [0.91 0.41], and bias is 0.7299999999999998\n",
            "Epoch 9, Optimized Weights are [0.9 0.4], and bias is 0.6999999999999997\n",
            "Epoch 10, Optimized Weights are [0.89 0.39], and bias is 0.6699999999999997\n",
            "Epoch 11, Optimized Weights are [0.88 0.38], and bias is 0.6399999999999997\n",
            "Epoch 12, Optimized Weights are [0.87 0.37], and bias is 0.6099999999999997\n",
            "Epoch 13, Optimized Weights are [0.86 0.36], and bias is 0.5799999999999996\n",
            "Epoch 14, Optimized Weights are [0.85 0.35], and bias is 0.5499999999999996\n",
            "Epoch 15, Optimized Weights are [0.84 0.34], and bias is 0.5199999999999996\n",
            "Epoch 16, Optimized Weights are [0.83 0.33], and bias is 0.48999999999999955\n",
            "Epoch 17, Optimized Weights are [0.82 0.32], and bias is 0.4599999999999995\n",
            "Epoch 18, Optimized Weights are [0.81 0.31], and bias is 0.4299999999999995\n",
            "Epoch 19, Optimized Weights are [0.8 0.3], and bias is 0.39999999999999947\n",
            "Epoch 20, Optimized Weights are [0.79 0.29], and bias is 0.36999999999999944\n",
            "Epoch 21, Optimized Weights are [0.78 0.28], and bias is 0.3399999999999994\n",
            "Epoch 22, Optimized Weights are [0.77 0.27], and bias is 0.3099999999999994\n",
            "Epoch 23, Optimized Weights are [0.76 0.26], and bias is 0.27999999999999936\n",
            "Epoch 24, Optimized Weights are [0.75 0.25], and bias is 0.24999999999999933\n",
            "Epoch 25, Optimized Weights are [0.74 0.24], and bias is 0.2199999999999993\n",
            "Epoch 26, Optimized Weights are [0.73 0.23], and bias is 0.18999999999999928\n",
            "Epoch 27, Optimized Weights are [0.72 0.22], and bias is 0.15999999999999925\n",
            "Epoch 28, Optimized Weights are [0.71 0.21], and bias is 0.12999999999999923\n",
            "Epoch 29, Optimized Weights are [0.7 0.2], and bias is 0.09999999999999924\n",
            "Epoch 30, Optimized Weights are [0.69 0.19], and bias is 0.06999999999999926\n",
            "Epoch 31, Optimized Weights are [0.68 0.18], and bias is 0.03999999999999925\n",
            "Epoch 32, Optimized Weights are [0.67 0.17], and bias is 0.009999999999999247\n",
            "Epoch 33, Optimized Weights are [0.66 0.16], and bias is -0.020000000000000753\n",
            "Epoch 34, Optimized Weights are [0.65 0.15], and bias is -0.04000000000000076\n",
            "Epoch 35, Optimized Weights are [0.64 0.14], and bias is -0.06000000000000076\n",
            "Epoch 36, Optimized Weights are [0.63 0.13], and bias is -0.08000000000000075\n",
            "Epoch 37, Optimized Weights are [0.62 0.12], and bias is -0.10000000000000074\n",
            "Epoch 38, Optimized Weights are [0.61 0.11], and bias is -0.12000000000000073\n",
            "Epoch 39, Optimized Weights are [0.6  0.11], and bias is -0.13000000000000073\n",
            "Epoch 40, Optimized Weights are [0.59 0.11], and bias is -0.14000000000000073\n",
            "Epoch 41, Optimized Weights are [0.58 0.11], and bias is -0.15000000000000074\n",
            "Epoch 42, Optimized Weights are [0.57 0.11], and bias is -0.16000000000000075\n",
            "Epoch 43, Optimized Weights are [0.56 0.11], and bias is -0.17000000000000076\n",
            "Epoch 44, Optimized Weights are [0.55 0.11], and bias is -0.18000000000000077\n",
            "Epoch 45, Optimized Weights are [0.54 0.11], and bias is -0.19000000000000078\n",
            "Epoch 46, Optimized Weights are [0.53 0.11], and bias is -0.2000000000000008\n",
            "Epoch 47, Optimized Weights are [0.52 0.11], and bias is -0.2100000000000008\n",
            "Epoch 48, Optimized Weights are [0.51 0.11], and bias is -0.2200000000000008\n",
            "Epoch 49, Optimized Weights are [0.5  0.11], and bias is -0.23000000000000081\n",
            "Epoch 50, Optimized Weights are [0.49 0.11], and bias is -0.24000000000000082\n",
            "Epoch 51, Optimized Weights are [0.48 0.11], and bias is -0.25000000000000083\n",
            "Epoch 52, Optimized Weights are [0.47 0.11], and bias is -0.26000000000000084\n",
            "Epoch 53, Optimized Weights are [0.46 0.11], and bias is -0.27000000000000085\n",
            "Epoch 54, Optimized Weights are [0.45 0.11], and bias is -0.28000000000000086\n",
            "Epoch 55, Optimized Weights are [0.44 0.11], and bias is -0.29000000000000087\n",
            "Epoch 56, Optimized Weights are [0.43 0.11], and bias is -0.3000000000000009\n",
            "Epoch 57, Optimized Weights are [0.42 0.11], and bias is -0.3100000000000009\n",
            "Epoch 58, Optimized Weights are [0.41 0.11], and bias is -0.3200000000000009\n",
            "Epoch 59, Optimized Weights are [0.4  0.11], and bias is -0.3300000000000009\n",
            "Epoch 60, Optimized Weights are [0.39 0.11], and bias is -0.3400000000000009\n",
            "Epoch 61, Optimized Weights are [0.38 0.11], and bias is -0.3500000000000009\n",
            "Epoch 62, Optimized Weights are [0.37 0.11], and bias is -0.36000000000000093\n",
            "Epoch 63, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 64, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 65, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 66, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 67, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 68, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 69, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 70, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 71, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 72, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 73, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 74, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 75, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 76, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 77, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 78, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 79, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 80, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 81, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 82, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 83, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 84, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 85, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 86, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 87, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 88, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 89, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 90, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 91, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 92, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 93, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 94, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 95, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 96, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 97, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 98, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 99, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Optimized Weights are [0.36 0.11] and bias is -0.37000000000000094\n",
            "Input: [0 0], Predictions: 0\n",
            "Input: [0 1], Predictions: 0\n",
            "Input: [1 0], Predictions: 0\n",
            "Input: [1 1], Predictions: 1\n"
          ]
        }
      ]
    }
  ]
}